#!/usr/bin/env bash
#
# Cyber Safer - Configuration File
# 
# Edit these settings to customize your setup
# Then run: source config.env
# Or: ./start.sh will automatically use these settings
#

# ========== MODEL CONFIGURATION ==========

# Which model to use
# Options:
#   - meta-llama/Llama-3.1-8B-Instruct (default, ~8GB RAM)
#   - meta-llama/Llama-3.2-3B-Instruct (smaller, ~4GB RAM)
#   - meta-llama/Llama-3.2-1B-Instruct (tiny, ~2GB RAM)
#   - Qwen/Qwen2.5-7B-Instruct (alternative, ~7GB RAM)
export CYBERS_MODEL="meta-llama/Llama-3.1-8B-Instruct"

# Quantization level (reduces memory usage)
# Options:
#   - 4  : 4-bit quantization (smallest, ~4GB VRAM)
#   - 8  : 8-bit quantization (medium, ~8GB VRAM)
#   - "" : No quantization (full precision, ~16GB VRAM)
export CYBERS_BITS="4"

# Default player/persona
# This is the AI personality used when not in a scenario
export CYBERS_PLAYER="players/mentor.json"

# ========== ADVANCED SETTINGS ==========

# HuggingFace cache directory
# Where to store downloaded models (can be large!)
# export HF_HOME="$HOME/.cache/huggingface"

# PyTorch CUDA memory management
# Helps prevent out-of-memory errors on GPU
# export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512"

# Number of threads for CPU inference
# export OMP_NUM_THREADS="8"

# ========== SERVER SETTINGS ==========

# Port to run the server on
export CYBERS_PORT="8021"

# Host to bind to (0.0.0.0 for external access, 127.0.0.1 for local only)
export CYBERS_HOST="127.0.0.1"

# ========== PRESETS ==========

# Uncomment one of these presets to use predefined configurations

# PRESET: Low Memory (for systems with <8GB RAM)
# export CYBERS_MODEL="meta-llama/Llama-3.2-1B-Instruct"
# export CYBERS_BITS="4"

# PRESET: Balanced (default, for systems with 8-16GB RAM)
# export CYBERS_MODEL="meta-llama/Llama-3.1-8B-Instruct"
# export CYBERS_BITS="4"

# PRESET: High Quality (for systems with 16GB+ RAM)
# export CYBERS_MODEL="meta-llama/Llama-3.1-8B-Instruct"
# export CYBERS_BITS="8"

# PRESET: CPU Only (no GPU)
# export CYBERS_MODEL="meta-llama/Llama-3.2-3B-Instruct"
# export CYBERS_BITS="8"

echo "âœ… Configuration loaded!"
echo "   Model: $CYBERS_MODEL"
echo "   Quantization: ${CYBERS_BITS}-bit"
echo "   Player: $CYBERS_PLAYER"
echo ""
echo "To apply: source config.env"
echo "Then run: ./start.sh"
